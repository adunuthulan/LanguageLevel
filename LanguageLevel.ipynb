{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LanguageLevel.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ApYxG2YlTMex"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adunuthulan/LanguageLevel/blob/master/LanguageLevel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3-PvH9Rj7Qg",
        "colab_type": "text"
      },
      "source": [
        "# **Analyzing The Reading Level of Text with Machine Learning**\n",
        "By Nirav Adunuthula\n",
        "Started Oct 11, 2019"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFuHQi3fScFA",
        "colab_type": "text"
      },
      "source": [
        "##Why Predict Reading Level?\n",
        "For beginnners, learning a language is difficult. You need to speak, hear, and read the language to gain full literacy. For people unable to join a class, the internet is a great resource for free material; however, there isn't always a clear guide for what books are at a person's level that will help them improve their literacy. The issue I've run into is as such: **how would one categorize writing into a reading level?**\n",
        "\n",
        "Here are some features off the top of my head that logically would correspond to reading level:\n",
        "* The complexity of the words used/the maturity level\n",
        "* The average word/sentence length\n",
        "* The use of complex punctuation/grammar (colons, dashes, etc.)\n",
        "\n",
        "There might be other features that we are not considering or that are not clear to us. For that, we can use Machine Learning. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE7QjB1zVubb",
        "colab_type": "text"
      },
      "source": [
        "## The Data\n",
        "\n",
        "But in order to use ML, we need Data. Books used pedalogically in schools have somewhat well defined levels of reading with the grade the books are taught at, \n",
        "so I shall use them as my training data. Words by themselves are difficult to categorize into reading levels ('the' is probably in every work of literature), so **I shall feed in chapters of books alongside the grade they are taught at as my data.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIE3t4URjx3M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3110be8b-d069-4c04-f341-41b15b3cf93e"
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gahS25gjblq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "85f9fa07-34b4-458f-f625-602c509b53a5"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import random\n",
        "\n",
        "print(\"Tensorflow version: \", tf.__version__)\n",
        "print(\"Hub version: \", hub.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version:  2.0.0\n",
            "Hub version:  0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6UFqHtijgtg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "441bbe68-1e17-460a-9b5a-654850b89966"
      },
      "source": [
        "nltk.download(\"book\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'book'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection book\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gzBsnd8j5k_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c0a166c7-2fe3-485f-8741-ed111cbc7fae"
      },
      "source": [
        "#mount drive when using Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qm_lQpKreNaa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a56a7a25-b548-47fc-eb8d-96c4af093a14"
      },
      "source": [
        "#import readingdata in a csv file and put it in a pandas data frame\n",
        "\n",
        "path = \"/content/drive/My Drive/Colab Notebooks/LanguageLevelData/CSV/readingdata.csv\"\n",
        "rd = pd.read_csv(path)\n",
        "print(rd)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                Text   ReadingLevel\n",
            "0  Pedro wants to ride his skateboard. Pedro has ...              1\n",
            "1  People eat shrimp. Shrimp comes from the ocean...              1\n",
            "2  Look at all of these big buildings! This is a ...              2\n",
            "3  The environment is all around you. Rocks, soil...              2\n",
            "4  Cactus pygmy-owls are little birds. They are a...              3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApYxG2YlTMex",
        "colab_type": "text"
      },
      "source": [
        "### Pre-processing the Data\n",
        "The data is in the form (String text, int grade_level). We will obtain some features from the data like number of sentences in each text and the number of times each word is repeated. We will ignore any punctuation and possibly discount some common words like 'and' or 'a' in the feature list we use to train a classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLpN-cQfkdrk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2f1cb18-780f-4791-b9cc-bec12c0ec3d6"
      },
      "source": [
        "#Preprocess the text data which is in the form (String text, int grade_level)\n",
        "sentences = []\n",
        "for row in rd.itertuples():\n",
        "  sentences.append(nltk.sent_tokenize(row[1].lower()))\n",
        "\n",
        "#get the number of sentences in each text for future feature processing\n",
        "num_sent = [len(sent) for sent in sentences]\n",
        "\n",
        "tokenized_sentences = []\n",
        "for row in rd.itertuples():\n",
        "  tokenized_sentences.append(nltk.word_tokenize(row[1].lower()))\n",
        "print(tokenized_sentences)\n",
        "\n",
        "#find the frequency of words in sentences\n",
        "word_freq = [nltk.FreqDist(t_sent) for t_sent in tokenized_sentences]\n",
        "print (\"Found %d unique word tokens in book 1\" % len(word_freq[0].items()))\n",
        "\n",
        "#Put the labels into an array and put the sentences with the labels\n",
        "rd_token = rd.copy()\n",
        "print(rd_token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['pedro', 'wants', 'to', 'ride', 'his', 'skateboard', '.', 'pedro', 'has', 'pads', 'for', 'his', 'knees', '.', 'he', 'also', 'has', 'pads', 'for', 'his', 'elbows', '.', 'he', 'has', 'pads', 'for', 'his', 'hands', '.', 'he', 'puts', 'on', 'his', 'helmet', '.', 'pedro', 'puts', 'on', 'his', 'safety', 'shoes', '.', 'he', 'has', 'his', 'skateboard', '.', 'let', \"'s\", 'have', 'fun', '!'], ['people', 'eat', 'shrimp', '.', 'shrimp', 'comes', 'from', 'the', 'ocean', '.', 'people', 'eat', 'clams', '.', 'clams', 'come', 'from', 'the', 'ocean', '.', 'people', 'eat', 'lobsters', '.', 'lobsters', 'come', 'from', 'the', 'ocean', '.', 'people', 'eat', 'small', 'fish', '.', 'small', 'fish', 'come', 'from', 'the', 'ocean', '.', 'people', 'eat', 'big', 'fish', '.', 'big', 'fish', 'come', 'from', 'the', 'ocean', '.', 'people', 'eat', 'mussels', '.', 'mussels', 'come', 'from', 'the', 'ocean', '.', 'people', 'eat', 'many', 'foods', 'from', 'the', 'ocean', '.'], ['look', 'at', 'all', 'of', 'these', 'big', 'buildings', '!', 'this', 'is', 'a', 'city', '.', 'a', 'city', 'is', 'an', 'urban', 'community', '.', 'an', 'urban', 'community', 'is', 'a', 'place', 'where', 'many', 'people', 'live', '.', 'do', 'you', 'know', 'what', 'these', 'big', 'buildings', 'are', '?', 'they', 'are', 'apartment', 'buildings', '.', 'many', 'people', 'in', 'urban', 'communities', 'live', 'in', 'apartments', '.', 'people', 'in', 'all', 'communities', 'work', '.', 'some', 'people', 'in', 'cities', 'work', 'in', 'factories', '.', 'factories', 'make', 'things', 'like', 'cars', ',', 'tools', ',', 'and', 'toys', '.', 'people', 'in', 'cities', 'may', 'work', 'in', 'offices', '.', 'many', 'people', 'from', 'the', 'suburbs', 'commute', 'to', 'urban', 'communities', 'to', 'work', '.', 'all', 'communities', 'have', 'people', 'who', 'help', 'others', 'stay', 'healthy', '.', 'cities', 'have', 'big', 'hospitals', 'that', 'can', 'provide', 'medical', 'care', 'to', 'many', 'people', '.', 'schools', 'and', 'churches', 'are', 'usually', 'bigger', 'in', 'cities', 'than', 'in', 'smaller', 'communities', '.', 'you', 'need', 'big', 'buildings', 'when', 'there', 'are', 'many', 'people', 'in', 'a', 'community', '.', 'how', 'do', 'people', 'get', 'from', 'place', 'to', 'place', 'in', 'a', 'city', '?', 'there', 'are', 'many', 'cars', 'and', 'trucks', 'in', 'an', 'urban', 'community', '.', 'there', 'are', 'also', 'taxicabs', ',', 'buses', ',', 'and', 'trains', '.', 'things', 'made', 'in', 'cities', 'are', 'shipped', 'to', 'other', 'places', 'every', 'day', '.', 'goods', 'from', 'rural', 'communities', 'such', 'as', 'fruits', 'and', 'vegetables', ',', 'are', 'shipped', 'in', 'to', 'cities', 'daily', '.', 'many', 'colleges', ',', 'museums', ',', 'and', 'parks', 'are', 'located', 'in', 'urban', 'communities', '.', 'people', 'go', 'to', 'cities', 'to', 'see', 'plays', ',', 'attend', 'concerts', ',', 'and', 'enjoy', 'art', '.', 'there', 'are', 'many', 'restaurants', ',', 'movie', 'theaters', ',', 'and', 'sports', 'facilities', 'in', 'urban', 'communities', '.', 'people', 'in', 'cities', 'have', 'many', 'places', 'to', 'go', 'for', 'fun', '!', 'now', 'you', 'know', 'more', 'about', 'life', 'in', 'an', 'urban', 'community', '.', 'many', 'people', 'live', 'in', 'cities', '.', 'cities', 'are', 'amazing', '!'], ['the', 'environment', 'is', 'all', 'around', 'you', '.', 'rocks', ',', 'soil', ',', 'sand', ',', 'plants', ',', 'and', 'animals', 'are', 'all', 'part', 'of', 'nature', '.', 'not', 'all', 'environments', 'are', 'alike', '.', 'this', 'is', 'a', 'jungle', '.', 'it', 'is', 'a', 'hot', ',', 'wet', 'place', ',', 'it', 'rains', 'often', 'here', '.', 'there', 'are', 'many', 'plants', 'and', 'animals', 'in', 'the', 'jungle', '.', 'have', 'you', 'ever', 'been', 'to', 'a', 'desert', '?', 'a', 'desert', 'environment', 'is', 'very', 'dry', 'and', 'can', 'be', 'very', 'hot', '.', 'the', 'plants', 'and', 'animals', 'that', 'make', 'their', 'homes', 'here', 'have', 'adapted', 'to', 'life', 'with', 'little', 'water', '.', 'look', 'at', 'the', 'beautiful', 'fall', 'colors', '!', 'these', 'leaves', 'will', 'be', 'gone', 'when', 'winter', 'arrives', '.', 'most', 'people', 'in', 'the', 'united', 'states', 'live', 'where', 'it', 'is', 'warn', 'in', 'the', 'summer', 'and', 'cold', 'in', 'the', 'winter', '.', 'some', 'environments', 'have', 'mountains', '.', 'others', 'have', 'rivers', ',', 'lakes', ',', 'or', 'oceans', '.', 'some', 'are', 'wet', ',', 'and', 'some', 'are', 'dry', '.', 'what', 'is', 'it', 'like', 'where', 'you', 'live', '?', 'people', 'use', 'what', 'they', 'get', 'from', 'nature', 'to', 'make', 'things', '.', 'the', 'wood', 'in', 'this', 'house', 'came', 'from', 'trees', '.', 'peoople', 'also', 'use', 'stones', 'to', 'build', 'homes', '.', 'can', 'you', 'think', 'of', 'other', 'things', 'make', 'from', 'wood', 'or', 'stone', '?', 'we', 'get', 'food', 'from', 'nature', '.', 'do', 'you', 'like', 'bread', ',', 'rice', ',', 'or', 'pasta', '?', 'all', 'those', 'things', 'come', 'from', 'plants', '.', 'plants', 'give', 'us', 'lots', 'of', 'tasty', 'foods', ',', 'including', 'all', 'the', 'fruits', 'and', 'vegetables', 'we', 'eat', '.', 'people', 'also', 'get', 'food', 'from', 'animals', '.', 'animals', 'are', 'a', 'part', 'of', 'nature', '.', 'we', 'get', 'fish', 'from', 'oceans', ',', 'lakes', ',', 'and', 'rivers', '.', 'we', 'eat', 'meat', 'from', 'cows', ',', 'pigs', '.', 'sheep', ',', 'goats', ',', 'and', 'chickens', '.', 'animals', 'also', 'give', 'us', 'eggs', ',', 'milk', ',', 'and', 'cheese', '.', 'people', 'need', 'clothing', '.', 'we', 'get', 'some', 'of', 'our', 'clothing', 'from', 'nature', '.', 'sheep', 'give', 'us', 'wool', '.', 'cotton', 'comes', 'from', 'cotton', 'plants', '.', 'leather', 'comes', 'from', 'cows', '.', 'what', 'clothes', 'do', 'you', 'wear', 'that', 'come', 'from', 'plants', 'or', 'animals', '?', 'people', 'do', \"n't\", 'always', 'keep', 'land', ',', 'water', ',', 'and', 'air', 'as', 'clean', 'as', 'it', 'should', 'be', '.', 'it', 'is', 'called', 'pollution', 'when', 'people', 'throw', 'trash', 'on', 'the', 'ground', 'or', 'into', 'water', '.', 'it', 'is', 'called', 'air', 'pollution', 'when', 'factories', 'and', 'cars', 'put', 'too', 'much', 'smoke', 'in', 'the', 'air', '.', 'we', 'get', 'food', ',', 'clothing', ',', 'and', 'shelter', 'from', 'nature', '.', 'people', ',', 'plants', ',', 'and', 'animals', 'need', 'a', 'clean', 'environment', '.', 'people', 'use', 'the', 'environment', '.', 'let', \"'s\", 'take', 'good', 'care', 'of', 'it', '!'], ['cactus', 'pygmy-owls', 'are', 'little', 'birds', '.', 'they', 'are', 'about', '6.5', 'inches', 'long', '(', '17', 'centimeters', ')', 'and', 'weigh', '2.5', 'ounces', '(', '62', 'grams', ')', '.', 'they', 'are', 'part', 'of', 'a', 'group', 'of', 'birds', 'called', 'raptors', '.', 'raptors', 'hunt', 'and', 'eat', 'other', 'animals', '.', 'the', 'raptor', 'group', 'includes', 'owls', ',', 'hawks', ',', 'and', 'eagles', '.', 'there', 'are', 'cactus', 'pygmy-owls', 'in', 'the', 'united', 'states', '.', 'they', 'live', 'in', 'desert', 'areas', 'in', 'texas', 'and', 'arizona', '.', 'cactus', 'pygmy-owls', 'may', 'be', 'small', 'birds', ',', 'but', 'they', 'are', 'good', 'hunters', '.', 'cactus', 'pygmy-owls', 'hunt', 'and', 'eat', 'birds', ',', 'lizards', ',', 'insects', ',', 'and', 'other', 'animals', '.', 'they', 'often', 'hunt', 'doves', 'that', 'are', 'twice', 'their', 'size', '.', 'do', 'you', 'know', 'anything', 'that', 'makes', 'these', 'owls', 'different', 'than', 'most', 'owls', '?', 'most', 'owls', 'hunt', 'at', 'night', '.', 'cactus', 'pygmy-owls', 'hunt', 'during', 'the', 'day', '.', 'cactus', 'pygmy-owls', 'build', 'their', 'nests', 'in', 'trees', 'or', 'cactus', 'plants', '.', 'they', 'often', 'make', 'their', 'nests', 'in', 'abandoned', 'holes', 'left', 'behind', 'by', 'woodpeckers', '.', 'coyotes', 'are', 'mammals', '.', 'they', 'look', 'like', 'small', 'wolves', '.', 'people', 'often', 'confuse', 'wolves', 'and', 'coyotes', '.', 'coyotes', 'that', 'live', 'in', 'the', 'desert', 'can', 'weigh', 'up', 'to', '25', 'pounds', '(', '11', 'kilograms', ')', '.', 'adults', 'are', 'usually', 'two', 'feet', 'tall', '(', '61', 'centimeters', ')', 'at', 'the', 'shoulder', '.', 'coyotes', 'average', 'about', '4', 'feet', '(', '122', 'centimeters', ')', 'in', 'length', '.', 'that', '4', 'feet', '(', '122', 'centimeters', ')', 'includes', 'a', 'coyote', \"'s\", 'body', 'and', 'tail', '.', 'coyotes', 'live', 'in', 'many', 'different', 'habitats', '.', 'they', 'live', 'throughout', 'most', 'of', 'north', 'america', '.', 'one', 'of', 'the', 'places', 'you', 'can', 'find', 'coyotes', 'is', 'in', 'deserts', '.', 'most', 'coyotes', 'live', 'alone', 'or', 'in', 'pairs', '.', 'sometimes', 'they', 'live', 'together', 'in', 'larger', 'groups', '.', 'coyotes', 'have', 'very', 'good', 'eyesight', '.', 'they', 'have', 'excellent', 'hearing', '.', 'they', 'have', 'a', 'very', 'good', 'sense', 'of', 'smell', '.', 'did', 'you', 'know', 'that', 'coyotes', 'will', 'eat', 'many', 'different', 'kinds', 'of', 'food', '?', 'omnivores', 'eat', 'plants', 'and', 'meat', '.', 'coyotes', 'are', 'omnivores', '.', 'they', 'prefer', 'meat', 'when', 'they', 'can', 'get', 'it', '.', 'coyotes', 'in', 'the', 'desert', 'eat', 'rodents', ',', 'lizards', ',', 'rabbits', ',', 'and', 'other', 'animals', '.', 'they', 'also', 'eat', 'fruit', ',', 'beans', ',', 'and', 'flowers', '.', 'do', 'you', 'know', 'the', 'name', 'of', 'these', 'small', 'animals', '?', 'they', 'are', 'centipedes', '.', 'centipedes', 'belong', 'to', 'a', 'group', 'of', 'animals', 'called', 'arthropods', '.', 'can', 'you', 'think', 'of', 'any', 'other', 'arthropods', '?', 'spiders', 'and', 'scorpions', 'are', 'arthropods', '.', 'insects', 'are', 'also', 'arthropods', '.', 'centipedes', 'can', 'be', 'found', 'in', 'many', 'places', 'all', 'around', 'the', 'world', '.', 'one', 'of', 'the', 'places', 'you', 'can', 'find', 'centipedes', 'is', 'deserts', '.', 'there', 'are', 'centipedes', 'that', 'live', 'in', 'all', 'four', 'of', 'the', 'deserts', 'in', 'the', 'united', 'states', '.', 'the', 'centipedes', 'in', 'these', 'pictures', 'are', 'giant', 'centipedes', '.', 'they', 'live', 'in', 'american', 'deserts', '.', 'they', 'can', 'be', 'up', 'to', '8', 'inches', '(', '20', 'centimeters', ')', 'long', '.', 'the', 'giant', 'centipedes', 'in', 'american', 'deserts', 'are', 'orange', '.', 'they', 'have', 'a', 'black', 'head', 'and', 'tail', '.', 'their', 'orange', 'color', 'warns', 'other', 'animals', 'to', 'leave', 'giant', 'centipedes', 'alone', '.', 'giant', 'centipedes', 'can', 'be', 'dangerous', 'because', 'they', 'have', 'venom', 'in', 'their', 'front', 'two', 'legs', '.', 'they', 'use', 'that', 'venom', 'to', 'kill', 'prey', '.', 'they', 'hunt', 'and', 'eat', 'insects', ',', 'lizards', ',', 'frogs', ',', 'and', 'other', 'animals', '.', 'gila', 'monsters', 'are', 'reptiles', '.', 'they', 'live', 'in', 'deserts', '.', 'they', 'have', 'big', 'heads', '.', 'they', 'have', 'colorful', 'bodies', 'and', 'thick', ',', 'short', 'tails', '.', 'they', 'store', 'water', 'and', 'fat', 'in', 'their', 'tails', '.', 'gila', 'monsters', 'are', 'big', 'lizards', '.', 'adults', 'can', 'be', '2', 'feet', 'long', '(', '61', 'centimeters', ')', '.', 'adults', 'can', 'weigh', 'up', 'to', '5', 'pounds', '(', '2.3', 'kilograms', ')', '.', 'did', 'you', 'know', 'that', 'gila', 'monsters', 'make', 'venom', '?', 'they', 'are', 'the', 'only', 'venomous', 'lizards', 'in', 'the', 'united', 'states', '.', 'gila', 'monsters', 'can', 'be', 'found', 'in', 'the', 'sonoran', ',', 'mojave', ',', 'and', 'chihuahuan', 'deserts', '.', 'all', 'of', 'those', 'deserts', 'are', 'in', 'the', 'southwestern', 'part', 'of', 'the', 'united', 'states', '.', 'gila', 'monsters', 'are', 'predators', '.', 'they', 'use', 'their', 'venom', 'when', 'hunting', '.', 'they', 'hunt', 'and', 'eat', 'different', 'animals', '.', 'they', 'hunt', 'and', 'eat', 'rodents', ',', 'rabbits', ',', 'and', 'birds', '.', 'they', 'even', 'eat', 'other', 'lizards', '.', 'gila', 'woodpeckers', 'are', 'birds', 'that', 'live', 'in', 'some', 'deserts', '.', 'they', 'can', 'be', 'found', 'in', 'the', 'deserts', 'of', 'the', 'southwestern', 'united', 'states', '.', 'they', 'can', 'also', 'be', 'found', 'in', 'desert', 'areas', 'in', 'the', 'country', 'of', 'mexico', '.', 'they', 'prefer', 'to', 'live', 'where', 'there', 'are', 'plenty', 'of', 'saguaro', 'cactus', 'plants', '.', 'gila', 'woodpeckers', 'are', 'not', 'big', 'birds', '.', 'adults', 'are', 'about', '9.5', 'inches', '(', '24', 'centimeters', ')', 'long', '.', 'average', 'adults', 'weigh', 'about', '2', 'ounces', '(', '57', 'grams', ')', '.', 'gila', 'woodpeckers', 'mainly', 'eat', 'insects', '.', 'they', 'also', 'eat', 'berries', 'and', 'cactus', 'fruit', '.', 'they', 'have', 'very', 'strong', 'head', 'and', 'neck', 'muscles', '.', 'those', 'strong', 'muscles', 'allow', 'them', 'to', 'peck', 'into', 'trees', 'and', 'cactus', 'plants', '.', 'they', 'peck', 'into', 'trees', 'and', 'cactus', 'plants', 'to', 'find', 'insects', 'to', 'eat', '.', 'they', 'also', 'peck', 'larger', 'holes', 'into', 'saguaro', 'cactus', 'plants', '.', 'they', 'build', 'their', 'nests', 'in', 'those', 'larger', 'holes', '.', 'the', 'large', 'holes', 'they', 'peck', 'out', 'for', 'their', 'nests', 'are', 'safe', ',', 'cool', 'places', 'to', 'raise', 'their', 'young.sometimes', 'there', 'is', 'more', 'than', 'one', 'name', 'for', 'the', 'same', 'animal', '.', 'the', 'snakes', 'in', 'these', 'photographs', 'are', 'called', 'glossy', 'snakes', '.', 'they', 'are', 'sometimes', 'called', 'faded', 'snakes', '.', 'they', 'are', 'nonvenomous', 'reptiles', '.', 'they', 'are', 'only', 'found', 'in', 'one', 'part', 'of', 'the', 'world', '.', 'they', 'are', 'found', 'only', 'in', 'the', 'southwestern', 'united', 'states', 'and', 'mexico', '.', 'adults', 'can', 'grow', 'up', 'to', '50', 'inches', '(', '130', 'centimeters', ')', 'long', '.', 'glossy', 'snakes', 'have', 'smooth', ',', 'glossy', 'scales', '.', 'they', 'normally', 'live', 'in', 'burrows', '.', 'they', 'hunt', 'at', 'night', '.', 'they', 'often', 'hunt', 'and', 'eat', 'lizards', '.', 'they', 'eat', 'different', 'kinds', 'of', 'lizards', '.', 'some', 'of', 'the', 'lizards', 'they', 'eat', 'are', 'desert', 'iguanas', 'and', 'zebra-tailed', 'lizards', '.', 'glossy', 'snakes', 'do', \"n't\", 'have', 'venom', '.', 'that', 'means', 'they', 'have', 'to', 'hunt', 'differently', 'than', 'venomous', 'snakes', 'do', '.', 'glossy', 'snakes', 'are', 'constrictors', '.', 'glossy', 'snakes', 'sneak', 'up', 'on', 'their', 'prey', '.', 'they', 'then', 'wrap', 'their', 'body', 'around', 'the', 'animal', 'they', 'are', 'hunting', '.', 'they', 'squeeze', 'their', 'prey', 'so', 'it', 'can', 'not', 'breathe', '.', 'all', 'snakes', 'that', 'hunt', 'using', 'this', 'method', 'are', 'called', 'constrictors', '.', 'desert', 'rosy', 'boas', 'are', 'also', 'nonvenomous', 'reptiles', '.', 'they', 'are', 'also', 'constrictors', '.', 'adults', 'can', 'be', 'up', 'to', '34', 'inches', '(', '86', 'centimeters', ')', 'long', '.', 'desert', 'rosy', 'boas', 'can', 'be', 'found', 'in', 'the', 'american', 'southwest', '.', 'they', 'can', 'also', 'be', 'found', 'in', 'the', 'country', 'of', 'mexico', '.', 'most', 'desert', 'rosy', 'boas', 'live', 'in', 'very', 'dry', 'habitats', '.', 'they', 'remain', 'deep', 'underground', 'when', 'there', 'is', 'no', 'rain', '.', 'they', 'become', 'active', 'hunters', 'when', 'it', 'rains', '.', 'desert', 'rosy', 'boas', 'are', 'carnivores', '.', 'they', 'are', 'predators', '.', 'desert', 'rosy', 'boas', 'have', 'very', 'powerful', 'bodies', '.', 'they', 'use', 'their', 'strong', 'bodies', 'to', 'squeeze', 'their', 'prey', 'to', 'death', '.', 'they', 'hunt', 'and', 'eat', 'mice', ',', 'rats', ',', 'rabbits', ',', 'and', 'other', 'small', 'animals', '.', 'do', 'you', 'know', 'why', 'desert', 'rosy', 'boas', 'do', 'not', 'chase', 'their', 'prey', '?', 'it', 'is', 'because', 'they', 'are', 'some', 'of', 'the', 'slowest', 'snakes', 'in', 'the', 'world', '.', 'that', \"'s\", 'why', 'they', 'wait', 'in', 'ambush', 'when', 'they', 'need', 'to', 'eat', '.']]\n",
            "Found 25 unique word tokens in book 1\n",
            "                                                Text   ReadingLevel\n",
            "0  Pedro wants to ride his skateboard. Pedro has ...              1\n",
            "1  People eat shrimp. Shrimp comes from the ocean...              1\n",
            "2  Look at all of these big buildings! This is a ...              2\n",
            "3  The environment is all around you. Rocks, soil...              2\n",
            "4  Cactus pygmy-owls are little birds. They are a...              3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNtu5EnYSi3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shuff(batch_size):\n",
        "  sent_shuff = sentences[0:batch_size]\n",
        "  return random.shuffle(sent_shuff)\n",
        "def batch(batch_size):\n",
        "  return sentences[0:batch_size]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BN4a7_C4eUyU",
        "colab_type": "text"
      },
      "source": [
        "###Using the Tensorflow Dataset Pipeline\n",
        "Instead of Pre-Processing the data into tokenized sentences for our own ML analysis, we can also transform the csv into a TF Dataset so it can be easily piped into TF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2z8ugGIYwPg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "4974b7a3-9e4b-4b74-ba9f-c84ad1c79105"
      },
      "source": [
        "target = rd.pop(' ReadingLevel')\n",
        "dataset = tf.data.Dataset.from_tensor_slices((rd.values[:, 0], target.values))\n",
        "\n",
        "for feat, targ in dataset.take(5):\n",
        "  print ('Features: {}, Target: {}'.format(feat, targ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features: b\"Pedro wants to ride his skateboard. Pedro has pads for his knees. he also has pads for his elbows. He has pads for his hands. He puts on his helmet. Pedro puts on his safety shoes. He has his skateboard. Let's have fun!\", Target: 1\n",
            "Features: b'People eat shrimp. Shrimp comes from the ocean. People eat clams. Clams come from the ocean. People eat lobsters. Lobsters come from the ocean. People eat small fish. Small fish come from the ocean. People eat big fish. Big fish come from the ocean. People eat mussels. Mussels come from the ocean. People eat many foods from the ocean.', Target: 1\n",
            "Features: b'Look at all of these big buildings! This is a city. A city is an urban community. An urban community is a place where many people live. Do you know what these big buildings are? They are apartment buildings. Many people in urban communities live in apartments. People in all communities work. Some people in cities work in factories. Factories make things like cars, tools, and toys. People in cities may work in offices. Many people from the suburbs commute to urban communities to work. All communities have people who help others stay healthy. Cities have big hospitals that can provide medical care to many people. Schools and churches are usually bigger in cities than in smaller communities. You need big buildings when there are many people in a community. How do people get from place to place in a city? There are many cars and trucks in an urban community. There are also taxicabs, buses, and trains. Things made in cities are shipped to other places every day. Goods from rural communities such as fruits and vegetables, are shipped in to cities daily. Many colleges, museums, and parks are located in urban communities. People go to cities to see plays, attend concerts, and enjoy art. There are many restaurants, movie theaters, and sports facilities in urban communities. People in cities have many places to go for fun! Now you know more about life in an urban community. Many people live in cities. Cities are amazing!', Target: 2\n",
            "Features: b\"The environment is all around you. Rocks, soil, sand, plants, and animals are all part of nature. Not all environments are alike. This is a jungle. It is a hot, wet place, It rains often here. There are many plants and animals in the jungle. Have you ever been to a desert? A desert environment is very dry and can be very hot. The plants and animals that make their homes here have adapted to life with little water. Look at the beautiful fall colors! These leaves will be gone when winter arrives. Most people in the UNited States live where it is warn in the summer and cold in the winter. Some environments have mountains. Others have rivers, lakes, or oceans. Some are wet, and some are dry. What is it like where you live? People use what they get from nature to make things. The wood in this house came from trees. Peoople also use stones to build homes. Can you think of other things make from wood or stone? We get food from nature. Do you like bread, rice, or pasta? All those things come from plants. Plants give us lots of tasty foods, including all the fruits and vegetables we eat. People also get food from animals. Animals are a part of nature. We get fish from oceans, lakes, and rivers. We eat meat from cows, pigs. sheep, goats, and chickens. Animals also give us eggs, milk, and cheese. People need clothing. We get some of our clothing from nature. SHeep give us wool. Cotton comes from cotton plants. Leather comes from cows. What clothes do you wear that come from plants or animals? People don't always keep land, water, and air as clean as it should be. It is called pollution when people throw trash on the ground or into water. It is called air pollution when factories and cars put too much smoke in the air. We get food, clothing, and shelter from nature. People, plants, and animals need a clean environment. People use the environment. Let's take good care of it!\", Target: 2\n",
            "Features: b\"Cactus pygmy-owls are little birds. They are about 6.5 inches long (17 centimeters) and weigh 2.5 ounces (62 grams). They are part of a group of birds called raptors. Raptors hunt and eat other animals. The raptor group includes owls, hawks, and eagles. There are cactus pygmy-owls in the United States. They live in desert areas in Texas and Arizona. Cactus pygmy-owls may be small birds, but they are good hunters. Cactus pygmy-owls hunt and eat birds, lizards, insects, and other animals. They often hunt doves that are twice their size. Do you know anything that makes these owls different than most owls? Most owls hunt at night. Cactus pygmy-owls hunt during the day. Cactus pygmy-owls build their nests in trees or cactus plants. They often make their nests in abandoned holes left behind by woodpeckers. Coyotes are mammals. They look like small wolves. People often confuse wolves and coyotes. Coyotes that live in the desert can weigh up to 25 pounds (11 kilograms). Adults are usually two feet tall (61 centimeters) at the shoulder. Coyotes average about 4 feet (122 centimeters) in length. That 4 feet (122 centimeters) includes a coyote's body and tail. Coyotes live in many different habitats. They live throughout most of North America. One of the places you can find coyotes is in deserts. Most coyotes live alone or in pairs. Sometimes they live together in larger groups. Coyotes have very good eyesight. They have excellent hearing. They have a very good sense of smell. Did you know that coyotes will eat many different kinds of food? Omnivores eat plants and meat. Coyotes are omnivores. They prefer meat when they can get it. Coyotes in the desert eat rodents, lizards, rabbits, and other animals. They also eat fruit, beans, and flowers. Do you know the name of these small animals? They are centipedes. Centipedes belong to a group of animals called arthropods. Can you think of any other arthropods? Spiders and scorpions are arthropods. Insects are also arthropods. Centipedes can be found in many places all around the world. One of the places you can find centipedes is deserts. There are centipedes that live in all four of the deserts in the United States. The centipedes in these pictures are giant centipedes. They live in American deserts. They can be up to 8 inches (20 centimeters) long. The giant centipedes in American deserts are orange. They have a black head and tail. Their orange color warns other animals to leave giant centipedes alone. Giant centipedes can be dangerous because they have venom in their front two legs. They use that venom to kill prey. They hunt and eat insects, lizards, frogs, and other animals. Gila monsters are reptiles. They live in deserts. They have big heads. They have colorful bodies and thick, short tails. They store water and fat in their tails. Gila monsters are big lizards. Adults can be 2 feet long (61 centimeters). Adults can weigh up to 5 pounds (2.3 kilograms). Did you know that Gila monsters make venom? They are the only venomous lizards in the United States. Gila monsters can be found in the Sonoran, Mojave, and Chihuahuan deserts. All of those deserts are in the southwestern part of the United States. Gila monsters are predators. They use their venom when hunting. They hunt and eat different animals. They hunt and eat rodents, rabbits, and birds. They even eat other lizards. Gila woodpeckers are birds that live in some deserts. They can be found in the deserts of the southwestern United States. They can also be found in desert areas in the country of Mexico. They prefer to live where there are plenty of saguaro cactus plants. Gila woodpeckers are not big birds. Adults are about 9.5 inches (24 centimeters) long. Average adults weigh about 2 ounces (57 grams). Gila woodpeckers mainly eat insects. They also eat berries and cactus fruit. They have very strong head and neck muscles. Those strong muscles allow them to peck into trees and cactus plants. They peck into trees and cactus plants to find insects to eat. They also peck larger holes into saguaro cactus plants. They build their nests in those larger holes. The large holes they peck out for their nests are safe, cool places to raise their young.Sometimes there is more than one name for the same animal. The snakes in these photographs are called glossy snakes. They are sometimes called faded snakes. They are nonvenomous reptiles. They are only found in one part of the world. They are found only in the southwestern United States and Mexico. Adults can grow up to 50 inches (130 centimeters) long. Glossy snakes have smooth, glossy scales. They normally live in burrows. They hunt at night. They often hunt and eat lizards. They eat different kinds of lizards. Some of the lizards they eat are desert iguanas and zebra-tailed lizards. Glossy snakes don't have venom. That means they have to hunt differently than venomous snakes do. Glossy snakes are constrictors. Glossy snakes sneak up on their prey. They then wrap their body around the animal they are hunting. They squeeze their prey so it cannot breathe. All snakes that hunt using this method are called constrictors. Desert rosy boas are also nonvenomous reptiles. They are also constrictors. Adults can be up to 34 inches (86 centimeters) long. Desert rosy boas can be found in the American Southwest. They can also be found in the country of Mexico. Most desert rosy boas live in very dry habitats. They remain deep underground when there is no rain. They become active hunters when it rains. Desert rosy boas are carnivores. They are predators. Desert rosy boas have very powerful bodies. They use their strong bodies to squeeze their prey to death. They hunt and eat mice, rats, rabbits, and other small animals. Do you know why desert rosy boas do not chase their prey? It is because they are some of the slowest snakes in the world. That's why they wait in ambush when they need to eat.\", Target: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI4TAvrGiUfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the percent of the data that goes into the training set VS validation set\n",
        "percentTV = .8\n",
        "\n",
        "#split up the data, using a percentage for the training set and all the data for testing\n",
        "num_take = tf.cast((len(rd)*percentTV), tf.int64)\n",
        "train_data = dataset.take(num_take)\n",
        "validation_data = dataset.skip(num_take).take(len(rd)-num_take)\n",
        "test_data = dataset\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIP--zS5OCzM",
        "colab_type": "text"
      },
      "source": [
        "PS : How to flatten a matrix into a single array\n",
        "\n",
        "`flattened = [val for sublist in sentences for val in sublist]`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbXxw4CrUGBf",
        "colab_type": "text"
      },
      "source": [
        "## Setting up a Model with Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ECLyJkIumpc",
        "colab_type": "text"
      },
      "source": [
        "#### Using Our Pre-Processed Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqjPSgyovKyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p3-lUyCuTDp",
        "colab_type": "text"
      },
      "source": [
        "#### Using TensorFlow-Hub\n",
        "Rather than training on features, we can also have the computer itself look at the text and reading levels and try and come up with its own way of classifying the text. We will use Tensorflow-Hub to have another means of processing the text into a shape keras can use.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA_Nu0pVlXty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "bb12c803-91e4-49f0-80e1-e492579c1ebf"
      },
      "source": [
        "#Set up the layers of the model. At first we will make the machine self-identify features of the text.\n",
        "\n",
        "embedding = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
        "hub_layer = hub.KerasLayer(embedding, input_shape=[], \n",
        "                           dtype=tf.string, trainable=True)\n",
        "\n",
        "#hub_layer()\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(hub_layer)\n",
        "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer (KerasLayer)     (None, 20)                400020    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                336       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 400,373\n",
            "Trainable params: 400,373\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgRvVlg6ZN60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#following the tensorflow.org tutorial on ML on text\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjLIOsYAflgW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "650526eb-4d21-421f-ad1b-e95a8a8af2cc"
      },
      "source": [
        "for a, b in train_data.batch(num_take).take(5):\n",
        "  print(\"Feature shape: \", a.shape)\n",
        "  print(\"Target shape: \", b.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature shape:  (4,)\n",
            "Target shape:  (4,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckYRRcMiZUpA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "691a75fc-0e36-4b94-a7ce-4abcb9608f33"
      },
      "source": [
        "history = model.fit(train_data.shuffle(num_take).batch(2),\n",
        "                    epochs=4,\n",
        "                    validation_data=validation_data.batch(len(rd)-num_take),\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "2/2 [==============================] - 0s 20ms/step - loss: -7.6551 - accuracy: 0.5000 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/4\n",
            "2/2 [==============================] - 0s 19ms/step - loss: -9.0535 - accuracy: 0.5000 - val_loss: -52.7585 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/4\n",
            "2/2 [==============================] - 0s 16ms/step - loss: -7.3674 - accuracy: 0.5000 - val_loss: -54.8707 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/4\n",
            "2/2 [==============================] - 0s 18ms/step - loss: -4.4431 - accuracy: 0.5000 - val_loss: -56.9723 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9-L_T7jozDq",
        "colab_type": "text"
      },
      "source": [
        "And let's see how the model performs. Two values will be returned. Loss (a number which represents our error, lower values are better), and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESeGOpqxoua-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "98dd5f1f-aa39-478d-864a-0ee6b9f18397"
      },
      "source": [
        "results = model.evaluate(test_data.batch(5), verbose=2)\n",
        "\n",
        "for name, value in zip(model.metrics_names, results):\n",
        "  print(\"%s: %.3f\" % (name, value))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 - 0s - loss: -5.6327e-01 - accuracy: 0.4000\n",
            "loss: -0.563\n",
            "accuracy: 0.400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKoS8Qe9R0Ug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "moun"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}