{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LanguageLevel.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ApYxG2YlTMex"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adunuthulan/LanguageLevel/blob/master/LanguageLevel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3-PvH9Rj7Qg",
        "colab_type": "text"
      },
      "source": [
        "# **Analyzing The Reading Level of Text with Machine Learning**\n",
        "By Nirav Adunuthula\n",
        "Started Oct 11, 2019"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZX6g7b7cpuo",
        "colab_type": "text"
      },
      "source": [
        "I have recently wondered if the saying, \"All news articles are written at a fourth grade reading level\", was true. This is a project to try and answer that question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFuHQi3fScFA",
        "colab_type": "text"
      },
      "source": [
        "##Why Predict Reading Level?\n",
        "For beginnners, learning a language is difficult. You need to speak, hear, and read the language to gain full literacy. For people unable to join a class, the internet is a great resource for free material; however, there isn't always a clear guide for what books are at a person's level that will help them improve their literacy. The issue I've run into is as such: **how would one categorize writing into a reading level?**\n",
        "\n",
        "Here are some features off the top of my head that logically would correspond to reading level:\n",
        "* The complexity of the words used/the maturity level\n",
        "* The average word/sentence length\n",
        "* The use of complex punctuation/grammar (colons, dashes, etc.)\n",
        "\n",
        "The company Lexile has a tool to determine the reading level of a text, and they use an algorithm based upon similar features. The info for this analyzer can be found [here](https://lexile.com/educators/tools-to-support-reading-at-school/tools-to-determine-a-books-complexity/).\n",
        "\n",
        "There might be other features that we are not considering or that are not clear to us. For that, we can use Machine Learning. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE7QjB1zVubb",
        "colab_type": "text"
      },
      "source": [
        "## The Data\n",
        "\n",
        "But in order to use ML, we need Data. Books used pedalogically in schools have somewhat well defined levels of reading with the grade the books are taught at, \n",
        "so I shall use them as my training data. Words by themselves are difficult to categorize into reading levels ('the' is probably in every work of literature), so **I shall feed in chapters of books alongside the grade they are taught at as my data.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIE3t4URjx3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gahS25gjblq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f3958063-ca13-4a52-f58d-00ba699ac911"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import random\n",
        "\n",
        "print(\"Tensorflow version: \", tf.__version__)\n",
        "print(\"Hub version: \", hub.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version:  2.3.0\n",
            "Hub version:  0.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6UFqHtijgtg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b6924a53-b77a-4b46-ee29-137cf61ec7b4"
      },
      "source": [
        "nltk.download(\"book\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'book'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection book\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gzBsnd8j5k_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "f84a48e3-f39f-4040-eea5-865187847a36"
      },
      "source": [
        "#mount drive when using Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qm_lQpKreNaa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "0ad6a301-5aa5-4601-edd6-a2e81f0ff258"
      },
      "source": [
        "#import readingdata in a csv file and put it in a pandas data frame\n",
        "\n",
        "path = \"/content/drive/My Drive/Colab Notebooks/LanguageLevelData/CSV/readingdata.csv\"\n",
        "rd = pd.read_csv(path)\n",
        "print(rd)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                Text   ReadingLevel\n",
            "0  Pedro wants to ride his skateboard. Pedro has ...              1\n",
            "1  People eat shrimp. Shrimp comes from the ocean...              1\n",
            "2  Look at all of these big buildings! This is a ...              2\n",
            "3  The environment is all around you. Rocks, soil...              2\n",
            "4  Cactus pygmy-owls are little birds. They are a...              3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApYxG2YlTMex",
        "colab_type": "text"
      },
      "source": [
        "### Pre-processing the Data\n",
        "The data is in the form (String text, int grade_level). We will obtain some features from the data like number of sentences in each text and the number of times each word is repeated. We will ignore any punctuation and possibly discount some common words like 'and' or 'a' in the feature list we use to train a classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLpN-cQfkdrk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "8e48ca38-3efd-4b2a-ebdc-ba643e176567"
      },
      "source": [
        "#Preprocess the text data which is in the form (String text, int grade_level)\n",
        "\n",
        "target_labels = rd.loc[:,' ReadingLevel'].values.tolist() #book target labels\n",
        "print(\"Target Labels: \", target_labels)\n",
        "\n",
        "sentences = [] #sentences for each book\n",
        "labeled_sentences = [] #each sentence and the reading level associated with it\n",
        "\n",
        "for row in rd.itertuples():\n",
        "  sentences.append(nltk.sent_tokenize(row[1].lower()))\n",
        "  labeled_sentences.append((sent, row[2]) for sent in sentences[-1])\n",
        "\n",
        "#the number of sentences in each text\n",
        "num_sents = [len(sent) for sent in sentences] \n",
        "\n",
        "#tokenize text without punctuation\n",
        "tokenized_text = [] \n",
        "for row in rd.itertuples():\n",
        "  tokenized_text.append([w for w in nltk.word_tokenize(row[1].lower()) if w.isalnum()])\n",
        "print(tokenized_text[0])\n",
        "\n",
        "num_words = [len(words) for words in tokenized_text] #the number of words in a book\n",
        "\n",
        "#get the average words per sentence in each text\n",
        "avg_book_sentence_length = [w/s for w, s in zip(num_words, num_sents)]\n",
        "print (\"Book 1 has %d words on average.\" % avg_sentence_length[0])\n",
        "print(\"AAA:\", len(avg_book_sentence_length))\n",
        "\n",
        "#find the frequency of words in sentences\n",
        "word_freq = [nltk.FreqDist(t_sent) for t_sent in tokenized_text]\n",
        "print (\"Found %d unique word tokens in book 1\" % len(word_freq[0].items()))\n",
        "\n",
        "#get aggregate data depending on level\n",
        "num_books = dict()\n",
        "avg_words = dict()\n",
        "avg_sents = dict()\n",
        "for i, label in enumerate(target_labels):\n",
        "  num_books.update({label: num_books.get(label, 0) + 1})\n",
        "  avg_words.update({label: avg_words.get(label, 0) + num_words[i]})\n",
        "  avg_sents.update({label: avg_sents.get(label, 0) + num_sents[i]})\n",
        "\n",
        "for label in num_books.keys():\n",
        "  avg_words[label]/=num_books[label]\n",
        "  avg_sents[label]/=num_books[label]\n",
        "\n",
        "print(avg_sents)\n",
        "\n",
        "feature_list = pd.DataFrame()\n",
        "feature_list[\"bookID\"] = [x for x in range(len(rd))]\n",
        "feature_list[\"num_words\"] = num_words\n",
        "feature_list[\"num_sents\"] = num_sents\n",
        "feature_list[\"sent_length\"] = avg_book_sentence_length\n",
        "\n",
        "print(feature_list)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target Labels:  [1, 1, 2, 2, 3]\n",
            "['pedro', 'wants', 'to', 'ride', 'his', 'skateboard', 'pedro', 'has', 'pads', 'for', 'his', 'knees', 'he', 'also', 'has', 'pads', 'for', 'his', 'elbows', 'he', 'has', 'pads', 'for', 'his', 'hands', 'he', 'puts', 'on', 'his', 'helmet', 'pedro', 'puts', 'on', 'his', 'safety', 'shoes', 'he', 'has', 'his', 'skateboard', 'let', 'have', 'fun']\n",
            "Book 1 has 5 words on average.\n",
            "AAA: 5\n",
            "Found 22 unique word tokens in book 1\n",
            "{1: 10.5, 2: 35.5, 3: 121.0}\n",
            "   bookID  num_words  num_sents  sent_length\n",
            "0       0         43          8     5.375000\n",
            "1       1         59         13     4.538462\n",
            "2       2        246         28     8.785714\n",
            "3       3        348         43     8.093023\n",
            "4       4       1000        121     8.264463\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOJhrQOtFRkB",
        "colab_type": "text"
      },
      "source": [
        "Let's plot some of the dataset's metrics to get an understanding of our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzotfBds0xC8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "bfccc9ba-2b78-4c69-8694-6a7e739e109e"
      },
      "source": [
        "def plot_avg_words():\n",
        "    x, y = zip(*sorted(avg_words.items()))\n",
        "    \n",
        "    plt.bar(x, y)\n",
        "    plt.xlabel('Reading Level')\n",
        "    plt.ylabel('Avg Words')\n",
        "    plt.title('Avg Words per Reading Level')\n",
        "    plt.show()\n",
        "\n",
        "def plot_avg_sents():\n",
        "    x, y = zip(*sorted(avg_sents.items()))\n",
        "    \n",
        "    plt.bar(x, y)\n",
        "    plt.xlabel('Reading Level')\n",
        "    plt.ylabel('Avg Sentence Length')\n",
        "    plt.title('Avg Sentence Length per Reading Level')\n",
        "    plt.show()\n",
        "\n",
        "plot_avg_words()\n",
        "plot_avg_sents()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNtu5EnYSi3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shuff(batch_size):\n",
        "  sent_shuff = sentences[0:batch_size]\n",
        "  return random.shuffle(sent_shuff)\n",
        "def batch(batch_size):\n",
        "  return sentences[0:batch_size]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BN4a7_C4eUyU",
        "colab_type": "text"
      },
      "source": [
        "###Using the Tensorflow Dataset Pipeline\n",
        "Instead of Pre-Processing the data into tokenized sentences for our own ML analysis, we can also transform the csv into a TF Dataset so it can be easily piped into TF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2z8ugGIYwPg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "c456d14f-6d10-49f8-88d5-45849d52f1fd"
      },
      "source": [
        "target = rd.pop(' ReadingLevel')\n",
        "embedded_dataset = tf.data.Dataset.from_tensor_slices((rd.values[:, 0], target.values))\n",
        "processed_dataset = tf.data.Dataset.from_tensor_slices((feature_list.values[:, 1:], target.values))\n",
        "\n",
        "for feat, targ in embedded_dataset.take(3):\n",
        "  print ('Features: {}, Target: {}'.format(feat, targ))\n",
        "\n",
        "for feat, targ in processed_dataset.take(3):\n",
        "  print ('Features: {}, Target: {}'.format(feat, targ))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Features: b\"Pedro wants to ride his skateboard. Pedro has pads for his knees. he also has pads for his elbows. He has pads for his hands. He puts on his helmet. Pedro puts on his safety shoes. He has his skateboard. Let's have fun!\", Target: 1\n",
            "Features: b'People eat shrimp. Shrimp comes from the ocean. People eat clams. Clams come from the ocean. People eat lobsters. Lobsters come from the ocean. People eat small fish. Small fish come from the ocean. People eat big fish. Big fish come from the ocean. People eat mussels. Mussels come from the ocean. People eat many foods from the ocean.', Target: 1\n",
            "Features: b'Look at all of these big buildings! This is a city. A city is an urban community. An urban community is a place where many people live. Do you know what these big buildings are? They are apartment buildings. Many people in urban communities live in apartments. People in all communities work. Some people in cities work in factories. Factories make things like cars, tools, and toys. People in cities may work in offices. Many people from the suburbs commute to urban communities to work. All communities have people who help others stay healthy. Cities have big hospitals that can provide medical care to many people. Schools and churches are usually bigger in cities than in smaller communities. You need big buildings when there are many people in a community. How do people get from place to place in a city? There are many cars and trucks in an urban community. There are also taxicabs, buses, and trains. Things made in cities are shipped to other places every day. Goods from rural communities such as fruits and vegetables, are shipped in to cities daily. Many colleges, museums, and parks are located in urban communities. People go to cities to see plays, attend concerts, and enjoy art. There are many restaurants, movie theaters, and sports facilities in urban communities. People in cities have many places to go for fun! Now you know more about life in an urban community. Many people live in cities. Cities are amazing!', Target: 2\n",
            "Features: [43.     8.     5.375], Target: 1\n",
            "Features: [59.         13.          4.53846154], Target: 1\n",
            "Features: [246.          28.           8.78571429], Target: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI4TAvrGiUfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the percent of the data that goes into the training set VS validation set\n",
        "percentTV = .8\n",
        "\n",
        "#split up the data, using a percentage for the training set and all the data for testing\n",
        "num_take = tf.cast((len(rd)*percentTV), tf.int64)\n",
        "train_data = (embedded_dataset.take(num_take), processed_dataset.take(num_take))\n",
        "validation_data = (embedded_dataset.skip(num_take).take(len(rd)-num_take), \n",
        "                   processed_dataset.skip(num_take).take(len(rd)-num_take))\n",
        "test_data = (embedded_dataset, processed_dataset)\n"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIP--zS5OCzM",
        "colab_type": "text"
      },
      "source": [
        "PS : How to flatten a matrix into a single array\n",
        "\n",
        "`flattened = [val for sublist in sentences for val in sublist]`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbXxw4CrUGBf",
        "colab_type": "text"
      },
      "source": [
        "## Setting up a Model with Tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PALUiYUQ5iQ6",
        "colab_type": "text"
      },
      "source": [
        "I will be using the Keras Functional model that allows for a more complex model architecture. \n",
        "\n",
        "My first input will be the words themselves, and that section of the model will predict the class (grade level) based upon features it finds. The words will be encoded by a THub word encoding layer, and then passed through a few dense layers. \n",
        "\n",
        "The second section of the model will take the word/sentence length, complexity/maturity, etc. as Inputs (features that I find)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ECLyJkIumpc",
        "colab_type": "text"
      },
      "source": [
        "#### Using Our Pre-Processed Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqjPSgyovKyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://keras.io/guides/functional_api/\n",
        "processed_input = keras.Input(shape=(3, ), name = \"processed_input\")"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p3-lUyCuTDp",
        "colab_type": "text"
      },
      "source": [
        "#### Using TensorFlow-Hub\n",
        "Rather than training on features, we can also have the computer itself look at the text and reading levels and try and come up with its own way of classifying the text. We will use Tensorflow-Hub to have another means of processing the text into a shape keras can use.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA_Nu0pVlXty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "b4fbab15-7f35-48a2-e790-7f8172acfa88"
      },
      "source": [
        "#Set up the layers of the model using the Sequential API.\n",
        "\n",
        "embedding = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
        "hub_layer = hub.KerasLayer(embedding, input_shape=[], \n",
        "                           dtype=tf.string, trainable=True)\n",
        "\n",
        "#hub_layer()\n",
        "\n",
        "embedded_model = tf.keras.Sequential()\n",
        "\n",
        "embedded_model.add(hub_layer)\n",
        "embedded_model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
        "embedded_model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "embedded_model.summary()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f667d2ceae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f667d2ceae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f667d2cb510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7f667d2cb510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer_18 (KerasLayer)  (None, 20)                400020    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 16)                336       \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 400,373\n",
            "Trainable params: 400,373\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgRvVlg6ZN60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#following the tensorflow.org tutorial on ML on text\n",
        "embedded_model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oa_rYYOPUyv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mergedOut = tf.keras.layers.Concatenate()([embedded_model.output, processed_input])\n",
        "mergedOut = tf.keras.layers.Dense(1, activation='sigmoid') (mergedOut)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ly_4VtbSCZf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "0b72f09c-e5b0-44d2-b479-b3c8ae083610"
      },
      "source": [
        "model = tf.keras.Model([embedded_model.input, processed_input], mergedOut)\n",
        "model.summary()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "keras_layer_18_input (InputLaye [(None,)]            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer_18 (KerasLayer)     (None, 20)           400020      keras_layer_18_input[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 16)           336         keras_layer_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 1)            17          dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "processed_input (InputLayer)    [(None, 3)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 4)            0           dense_6[0][0]                    \n",
            "                                                                 processed_input[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 1)            5           concatenate[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 400,378\n",
            "Trainable params: 400,378\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQ05yZLLTStT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjLIOsYAflgW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bb4e554b-02b3-4601-863b-ee38ace9adec"
      },
      "source": [
        "for a, b in train_data.batch(num_take).take(5):\n",
        "  print(\"Feature shape: \", a.shape)\n",
        "  print(\"Target shape: \", b.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature shape:  (4,)\n",
            "Target shape:  (4,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_QX7gdLTiU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(train_data[0].shuffle(num_take).batch(2),\n",
        "                    epochs=4,\n",
        "                    validation_data=validation_data[0].batch(len(rd)-num_take),\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9-L_T7jozDq",
        "colab_type": "text"
      },
      "source": [
        "And let's see how the model performs. Two values will be returned. Loss (a number which represents our error, lower values are better), and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESeGOpqxoua-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "964de2ce-0e52-48d7-8ff6-3f11face681c"
      },
      "source": [
        "results = model.evaluate(test_data.batch(5), verbose=2)\n",
        "\n",
        "for name, value in zip(model.metrics_names, results):\n",
        "  print(\"%s: %.3f\" % (name, value))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 - 0s - loss: -6.8731e-01 - accuracy: 0.4000\n",
            "loss: -0.687\n",
            "accuracy: 0.400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKoS8Qe9R0Ug",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aea8de85-d745-49eb-9742-c86bcd213810"
      },
      "source": [
        "print(model.predict([\"A banana was walking down the road when he tripped into the water.\"]))\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.5794918]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}